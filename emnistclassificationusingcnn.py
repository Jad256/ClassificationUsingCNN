# -*- coding: utf-8 -*-
"""emnistclassificationusingcnn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/gist/Jad256/5d61102e98df924be9602fd572a7e78c/emnistclassificationusingcnn.ipynb
"""

pip install pytorch_lightning

pip install mlflow

pip install pyngrok

#run tracking UI in the background

get_ipython().system_raw("mlflow ui --port 8000 &") # run tracking UI in the background


#create remote tunnel using ngrok.com to allow local port access
from pyngrok import ngrok


#Terminate open tunnels if they exist
ngrok.kill()

# Setting the authtoken (optional)

#12 Get your authtoken from https://dashboard.ngrok.com/auth



NGROK_AUTH_TOKEN="2nD8iAP7eNTqnb1o1ApcaA9JtAm_xF93dbHNkRmp4drRYaUZ"

ngrok.set_auth_token(NGROK_AUTH_TOKEN)



# Open an HTTPs tunnel on port 5000 for http://localhost:8000

ngrok_tunnel = ngrok.connect(addr = "8000", proto = "http", bind_tls = True)

print("MLflow Tracking UI:", ngrok_tunnel.public_url)

import mlflow
import torch
import numpy as np
import pandas as pd

from torch.utils.data import Dataset, DataLoader

from google.colab import drive
drive.mount('/content/drive')

emnist_train_data = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/emnist-letters-train.csv", header=None)
emnist_test_data = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/emnist-letters-test.csv", header=None)

class EMNISTDataset (Dataset):

      def __init__(self, dataframe):

          self.images = torch.tensor(dataframe.iloc[:, 1:].values, dtype = torch.float32)

          self.labels = torch.tensor(dataframe.iloc[:, 0].values, dtype = torch.float32)

      def __len__(self):

        return len(self.images)

      def __getitem__(self, idx):

        images = self.images[idx]

        images = images / 255.0

        labels = self.labels [idx]

        return images, labels

emnist_test_data = emnist_test_data.sample(frac = 1) #shuffling the test dataset using .sample()

import torchvision
from torchvision.datasets import EMNIST
from torchvision.transforms import ToTensor
import pytorch_lightning as pl

train_data = EMNISTDataset(emnist_train_data)
test_data = EMNISTDataset(emnist_test_data)

from torch.utils.data import random_split

val_percent = 0.1
val_len = int(val_percent * len(train_data))

train_ds,val_ds = random_split(train_data, [len(train_data) - val_len, val_len])

batch_size = 64

train_dataloader = DataLoader(train_ds, batch_size, shuffle= True, drop_last= True, num_workers=1)

val_dataloader = DataLoader(val_ds, batch_size, num_workers=1)

test_dataloader = DataLoader(test_data, batch_size, num_workers=1)

len(train_dataloader), len(test_dataloader), len(val_dataloader)

import mlflow

experiment_id = mlflow.create_experiment(name = "emnist_letters_prediction_cnn")

mlflow.set_experiment(experiment_name = "emnist_letters_prediction_cnn")

import torch.optim as optim
import torch.nn as nn
from torchmetrics.functional import accuracy

class EmnistModel(pl.LightningModule):
    def __init__(self):
        super().__init__()

        self.criterion = nn.CrossEntropyLoss()

        self.network = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size = 3, padding = 1),
            nn.ReLU(),
            nn.Conv2d(32, 64, kernel_size = 3, padding = 1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2), # 64 * 14 * 14

            nn.Conv2d(64, 128, kernel_size = 3, padding = 1),
            nn.ReLU(),
            nn.Conv2d(128, 256, kernel_size = 3, padding = 1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2), #256 * 7 * 7

            nn.Flatten(),
            nn.Linear(256*7*7, 32),
            nn.ReLU(),

            nn.Linear(32, 64),
            nn.ReLU(),

            nn.Linear(64, 26)
        )

    def forward(self, xb):
        return self.network(xb.reshape(-1, 1, 28, 28))

    def configure_optimizers(self):
        return optim.Adam(self.parameters(), lr = 0.0001)

    def training_step(self, batch, batch_idx):
        x, y = batch
        y -= 1

        y_hat = self(x)
        loss = self.criterion(y_hat, y.long())
        pred = y_hat.argmax(dim = 1)

        acc = accuracy(pred, y, task = "multiclass", num_classes = 26)

        self.log("train_loss", loss, on_epoch = True, prog_bar = True)
        self.log("train_acc", acc, on_epoch = True, prog_bar = True)

        return loss

    def validation_step(self, batch, batch_idx):
        x, y = batch
        y -= 1

        y_hat = self(x)
        loss = self.criterion(y_hat, y.long())
        pred = y_hat.argmax(dim = 1)

        acc = accuracy(pred, y, task = "multiclass", num_classes = 26)

        self.log("valid_loss", loss, on_epoch = True, prog_bar = True)
        self.log("valid_acc", acc, on_epoch = True, prog_bar = True)

        return acc

    def test_step(self, batch, batch_idx):
        x, y = batch
        y -= 1

        y_hat = self(x)
        loss = self.criterion(y_hat, y.long())
        pred = y_hat.argmax(dim = 1)

        acc = accuracy(pred, y, task = "multiclass", num_classes = 26)

        self.log("test_loss", loss, logger = True)
        self.log("test_acc", acc, logger = True)

        return acc


    def predict_step(self, batch, batch_idx, dataloader_idx = 0):
        x, y = batch

        return self(x)

from mlflow.models.signature import ModelSignature
from mlflow.types.schema import ColSpec, Schema, TensorSpec
from pytorch_lightning.loggers import CSVLogger

emnist_model = EmnistModel()

logger = CSVLogger("logs", name = "emnist_letters_classification")

trainer = pl.Trainer(max_epochs = 10, logger = logger)

mlflow.pytorch.autolog(log_models = False)

with mlflow.start_run() as run:

    trainer.fit(emnist_model, train_dataloader, val_dataloader)
    trainer.test(dataloaders = test_dataloader)

    input_schema = Schema([TensorSpec(np.dtype(np.float32), (-1, 1, 28, 28))])
    output_schema = Schema([TensorSpec(np.dtype(np.float32), (-1, 26))])
    signature = ModelSignature(inputs = input_schema, outputs = output_schema)

    mlflow.pytorch.log_model(emnist_model, "emnist-letters-classifier-cnn-model", signature = signature)